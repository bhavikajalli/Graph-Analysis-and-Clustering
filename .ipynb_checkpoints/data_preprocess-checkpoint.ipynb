{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autocorrect import spell\n",
    "import itertools\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessTweet(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words_english = set(stopwords.words('english'))\n",
    "    stop_words_english.remove(\"not\") \n",
    "    \n",
    "    tweet = tweet.encode('utf-16', 'surrogatepass').decode('utf-16')\n",
    "    \n",
    "    #Remove Urls \n",
    "\n",
    "    tweet.replace(\"don't\",\"do not\")\n",
    "    tweet.replace(\"can't\",\"can not\")\n",
    "    tweet.replace(\"cant\",\"can not\")\n",
    "    tweet.replace(\"dont\",\"do not\")\n",
    "    tweet.replace(\"isn't\",\"is not\")\n",
    "    tweet.replace(\"won't\",\"will not\")\n",
    "    tweet.replace(\"shouldn't\",\"should not\")\n",
    "    tweet.replace(\"wouldn't\",\"would not\")\n",
    "    \n",
    "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet) \n",
    "    \n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    #Capture retweets\n",
    "    if tokens[0] == \"RT\":\n",
    "        retweet = tokens[1][1:]\n",
    "        tokens.remove(\"RT\")\n",
    "        tokens = tokens[1:]\n",
    "    \n",
    "    elif tokens[0] != \"RT\":\n",
    "        retweet = \"\"\n",
    "    \n",
    "    #Remove the final ellipses in a tweet\n",
    "    tokens = tokens[:-1]\n",
    "   \n",
    "    #Remove words with numbers in them\n",
    "    tweet = ' '.join(s for s in tokens if not any(c.isdigit() for c in s))\n",
    "    tweet = re.sub(r'([^a-zA-Z0-9])\\1{3,}',\"\", tweet)\n",
    "\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    remove_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in string.punctuation:\n",
    "            remove_tokens.append(token)\n",
    "        if token[0] == \"#\":\n",
    "            remove_tokens.append(token)\n",
    "        if token[0] == \"@\":\n",
    "            remove_tokens.append(token)\n",
    "        if not token.isalpha():\n",
    "            remove_tokens.append(token)\n",
    "    \n",
    "    cleaned_tokens = [token for token in tokens if token not in remove_tokens]\n",
    "    \n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in cleaned_tokens]\n",
    "    cleaned_tokens = [spell(token) for token in cleaned_tokens]\n",
    "    cleaned_tokens = [w.lower() for w in cleaned_tokens if not w.lower() in stop_words_english]\n",
    "    #cleaned_tokens = [stemmer.stem(token) for token in cleaned_tokens]\n",
    "    \n",
    "    return ' '.join(cleaned_tokens),retweet\n",
    "\n",
    "def preprocessLocation(dic):\n",
    "    geolocator = Nominatim()\n",
    "    loc_final = []\n",
    "    coordinates = []\n",
    "    try: \n",
    "        if 'tweet_location_city' in dic:\n",
    "            loc = geolocator.geocode(dic['tweet_location_city'],addressdetails=True,language='en')\n",
    "            if loc is None:\n",
    "                loc_final = []\n",
    "            else:\n",
    "                loc_str = str(loc)\n",
    "                loc_list = loc_str.split(',')\n",
    "                #print(loc.raw)\n",
    "                city = loc_list[0]\n",
    "                loc_final.append(city)\n",
    "                if not \"state\" in loc.raw[\"address\"]:\n",
    "                    state = \"\"\n",
    "                else:\n",
    "                    state = loc.raw[\"address\"][\"state\"]\n",
    "\n",
    "                if not \"country\" in loc.raw[\"address\"]:\n",
    "                    country = \"\"\n",
    "                else:\n",
    "                    country = loc.raw[\"address\"][\"country\"]\n",
    "\n",
    "                loc_final.append(state)\n",
    "                loc_final.append(country)\n",
    "                location = city + \",\" + state + \",\" +country\n",
    "                c = geolocator.geocode(location)\n",
    "                if c != None:\n",
    "                    coordinates.append(str(c.latitude))\n",
    "                    coordinates.append(str(c.longitude))\n",
    "\n",
    "\n",
    "        elif dic['location']!= \"\":\n",
    "            loc = geolocator.geocode(dic['location'],addressdetails=True,language='en')\n",
    "            if loc is None:\n",
    "                loc_final = []\n",
    "            else:\n",
    "                loc_str = str(loc)\n",
    "                loc_list = loc_str.split(',')\n",
    "                #print(loc.raw)\n",
    "                city = loc_list[0]\n",
    "                loc_final.append(city)\n",
    "                if not \"state\" in loc.raw[\"address\"]:\n",
    "                    state = \"\"\n",
    "                else:\n",
    "                    state = loc.raw[\"address\"][\"state\"]\n",
    "\n",
    "                if not \"country\" in loc.raw[\"address\"]:\n",
    "                    country = \"\"\n",
    "                else:\n",
    "                    country = loc.raw[\"address\"][\"country\"]\n",
    "\n",
    "                loc_final.append(state)\n",
    "                loc_final.append(country)\n",
    "                location = city + \",\" + state + \",\" +country\n",
    "                c = geolocator.geocode(location)\n",
    "                if c != None:\n",
    "                    coordinates.append(str(c.latitude))\n",
    "                    coordinates.append(str(c.longitude))\n",
    "        \n",
    "        return loc_final,coordinates\n",
    "        \n",
    "    except GeocoderTimedOut:\n",
    "        return preprocessLocation(dic)\n",
    "\n",
    "def write_data(lines_data,outfile):\n",
    "    i = 0\n",
    "    for line in lines_data[809:]:\n",
    "        #print(line)\n",
    "        dic = json.loads(line)\n",
    "        name  = dic[\"screen_name\"]\n",
    "        text,retweet = preprocessTweet(dic[\"text\"])\n",
    "        if \"hashtags_in_the_tweet\" in dic:        \n",
    "            hashtags = dic[\"hashtags_in_the_tweet\"]\n",
    "        else:\n",
    "            hashtags = []\n",
    "\n",
    "        if \"Mentions_in_the_tweet\" in dic:     \n",
    "            mentions = dic[\"Mentions_in_the_tweet\"]\n",
    "        else:\n",
    "            mentions = []\n",
    "        if \"retweet_count\" in dic:\n",
    "            retweet_count = dic[\"retweet_count\"]\n",
    "        else:\n",
    "            retweet_count = 0\n",
    "\n",
    "        if \"replied_to\" in dic:\n",
    "            replied_to = dic[\"replied_to\"]\n",
    "            if replied_to != 'null':\n",
    "                replied_to = dic[\"replied_to\"]\n",
    "            else:\n",
    "                replied_to == 'null'\n",
    "        else:\n",
    "            replied_to == 'null'\n",
    "\n",
    "        #loc_final,coordinates = preprocessLocation(dic)\n",
    "        loc = dic[\"location\"]\n",
    "        loc_final = loc.split(\",\")\n",
    "        #print(loc_final)\n",
    "\n",
    "        #print(coordinates)    \n",
    "        #row = name + \",\" + text + \",\" + retweet + \",\" + '-'.join(mentions) + \",\" + '-'.join(hashtags) + \",\" + str(retweet_count) + \",\" + str(replied_to) +\",\"+ '-'.join(loc_final) + \",\" + ','.join(coordinates) + \"\\n\"\n",
    "        row = name + \",\" + text + \",\" + retweet + \",\" + '-'.join(mentions) + \",\" + '-'.join(hashtags) + \",\" + str(retweet_count) + \",\" + str(replied_to) +\",\"+ '-'.join(loc_final) + \"\\n\"\n",
    "        outfile.write(row)\n",
    "\n",
    "        i += 1\n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "\n",
    "    outfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-i\", \"--inputFile\", type=string,help=\"The file containing the Raw Tweets\")\n",
    "parser.add_argument(\"-o\", \"--outputFile\", type=string,help=\"The name of the Output file to be generated\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_file = open(args.inputFile, encoding='utf-8')\n",
    "outfile = open(args.outputFile,'w')\n",
    "#writer = csv.writer(outfile)\n",
    "header = \"name,tweet,retweet,mentions,hashtags,retweet_count,replied_to,location\"\n",
    "outfile.write(header+ \"\\n\")\n",
    "\n",
    "lines_data = data_file.readlines() \n",
    "print(len(lines_data))\n",
    "write_data(lines_data,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
